{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import open\n",
    "import random\n",
    "\n",
    "# Importamos las funciones\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Importaciones del Fetis\n",
    "import pandas as pd #manejo de datos.\n",
    "from nltk.probability import FreqDist #gráficos de frecuencia.\n",
    "import matplotlib.pyplot as plt #mostrar figuras.\n",
    "from wordcloud import WordCloud #nube de palabras.\n",
    "from dateutil.parser import parse #analizar strings de fechas.\n",
    "import numpy as np #manejo numérico.\n",
    "from nltk.tokenize import RegexpTokenizer #separación por expresiones regulares.\n",
    "from nltk.corpus import stopwords #lista de stopwords.\n",
    "from nltk.stem.porter import PorterStemmer #obtener raíz de una palabra.\n",
    "from sklearn.feature_extraction.text import CountVectorizer #contador de palabras.\n",
    "from sklearn.model_selection import train_test_split #partición dataset.\n",
    "from sklearn.linear_model import LogisticRegression #regresión logística.\n",
    "from sklearn.metrics import accuracy_score #evaluación del clasificador.\n",
    "from sklearn.metrics import classification_report #evaluación del clasificador.\n",
    "from sklearn.naive_bayes import GaussianNB # Naive bayes\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DATAFRAME = False\n",
    "SAVE_FIG = False\n",
    "PROCESAR = False\n",
    "SEED = 42\n",
    "N_SAMPLES = 2500\n",
    "\n",
    "# Variables de los nombres de las columnas\n",
    "TITLE = 'title'\n",
    "TEXT = 'text'\n",
    "SUBJECT = 'subject'\n",
    "DATE = 'date'\n",
    "TRUE = 'true'\n",
    "\n",
    "PATH_MAIN = path.join(\"..\")\n",
    "PATH_DATA = path.join(PATH_MAIN, \"datos\")\n",
    "PATH_IMG = path.join(PATH_MAIN, \"imagenes\")\n",
    "PATH_LATEX = path.join(PATH_MAIN, \"latex\")\n",
    "\n",
    "PATH_TABLAS = path.join(PATH_LATEX, \"tablas\")\n",
    "\n",
    "PATH_FAKE = path.join(PATH_DATA, \"Fake.csv\")\n",
    "PATH_FAKE_PROS = path.join(PATH_DATA, \"Fake_procesado.csv\")\n",
    "\n",
    "PATH_TRUE = path.join(PATH_DATA, \"True.csv\")\n",
    "PATH_TRUE_PROS = path.join(PATH_DATA, \"True_procesado.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del dataframe\n",
    "\n",
    "En esta sección cargamos los DataFrames y además le ponemos una etiqueta de que si es una noticia verdadera o falsa, para posteriormente unir los DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame de True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de la columna que almacenará la \n",
    "# información de si es una noticia verdadera o falsa\n",
    "name_col = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos DataFrame\n",
    "df_true = pd.read_csv(PATH_TRUE)\n",
    "\n",
    "# Agregamos nueva columna\n",
    "df_true[name_col] = 1\n",
    "\n",
    "df_true.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame de Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos DataFrame\n",
    "df_fake = pd.read_csv(PATH_FAKE)\n",
    "\n",
    "# Agregamos nueva columna\n",
    "df_fake[name_col] = 0\n",
    "\n",
    "del name_col\n",
    "\n",
    "df_fake.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge entre DataFrames\n",
    "Unimos los DataFrames, ahora que se tiene una indexización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_true.append(df_fake, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo basta un dataframe pues comparten el nombre de las columnas\n",
    "columnas = list(df.columns)\n",
    "columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información de los datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Información de los datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos la información de las filas de los datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar los datos que no sean fechas\n",
    "En algunas filas de los DataFrames hay información etiquetada como fecha, cuando no corresponde a una fecha. Reemplazamos estos valores por un tipo de dato NaT y los dropeamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def is_date(string, fuzzy=False):\n",
    "    \"\"\"\n",
    "    Return whether the string can be interpreted as a date.\n",
    "\n",
    "    :Param string: str, string to check for date\n",
    "    :Param fuzzy: bool, ignore unknown tokens in string if True\n",
    "    \"\"\"\n",
    "    from dateutil.parser import parse\n",
    "    \n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat = np.datetime64('NaT')\n",
    "\n",
    "def nat_conversor(x): return pd.Timestamp(x) if is_date(x) else nat\n",
    "\n",
    "df_fake[\"date\"] = df_fake[\"date\"].apply(nat_conversor)\n",
    "df_true[\"date\"] = df_true[\"date\"].apply(nat_conversor)\n",
    "df[\"date\"] = df[\"date\"].apply(nat_conversor)\n",
    "\n",
    "L_df = [df_fake, df_true, df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_ in L_df:\n",
    "    df_.dropna(inplace=True)\n",
    "\n",
    "del nat_conversor, nat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables únicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio, la columna `'title'` y `'text'` no son ni númericas, ni categóricas. `'date'` es un tipo de variable temporal, mientras que `'subject'` es una variable categórica. \n",
    "\n",
    "Veamos cuantas variables categóricas diferentes hay para cada `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El dataset de noticias verdaderas posee las siguientes etiquetas:\")\n",
    "for label in pd.unique(df_true.subject):\n",
    "    print(f\"* {label}\")\n",
    "    \n",
    "print(\"\\nEl dataset de noticias falsas posee las siguientes etiquetas:\")\n",
    "for label in pd.unique(df_fake.subject):\n",
    "    print(f\"* {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_cantidad_por_categoria(df_, categoria):\n",
    "    cantidad = len(df_[df_.subject == categoria])\n",
    "    print(f\"La categoría {categoria} posee {cantidad} datos.\")\n",
    "    return None\n",
    "\n",
    "print(\"Cantidad de datos por categoría para las noticias verdaderas:\")\n",
    "for label in pd.unique(df_true.subject):\n",
    "    imprimir_cantidad_por_categoria(df_true, label)\n",
    "\n",
    "    \n",
    "print(\"\\nCantidad de datos por categoría para las noticias falsas:\")\n",
    "for label in pd.unique(df_fake.subject):\n",
    "    imprimir_cantidad_por_categoria(df_fake, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisar noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿A qué se refiere `'worldnews'`? Obtengamos una noticia de esta categoría para observarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def revisar_noticias(df, category, gap=5):\n",
    "    \"\"\"Entrega varias noticias de una categoría en específico.\n",
    "    'df' es el DataFrame, 'category' es la categoría que se quiere revisar\n",
    "    y 'gap' es el número de noticias que se quiere mostrar.\n",
    "    \"\"\"\n",
    "    df_ = df[df.subject == category]\n",
    "    df_.reset_index(inplace=True)\n",
    "    for i in range(gap):\n",
    "        print(\"Título:\", f'\"{df_.title[i]}\"')\n",
    "        print(\"Texto:\", f\"{df_.text[i]}\")\n",
    "        print(\"\\n\", \"-\" * 80, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "revisar_noticias(df_true, \"worldnews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos decir entonces que una noticia de `'worldnews'` es una noticia estadounidense, que se refiere c/r al resto del mundo mundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Existirá un equivalente en `fakenews`? Empecemos por revisar la categoría `News`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisar_noticias(df_fake, \"News\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parecen ser simplemente noticias estándar, nada relacionado con noticias del mundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisar_noticias(df_fake, \"politics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Revisemos con la categoría `Middle-east`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisar_noticias(df_fake, \"Middle-east\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parece tener relación con noticias del mundo. Veamos ahora la categoría `left-news`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisar_noticias(df_fake, 'left-news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusión de Panchito\n",
    "\n",
    "Con la última categoría tentativa a ser una noticia acerca del mundo, podemos concluir a priori que no hay noticias falsas acerca del resto del mundo. Con lo que una alternativa tentativa para que el algoritmo no sufra de overfitting, es el de eliminar esta categoría.\n",
    "\n",
    "El problema que tendríamos con esto, es quedarnos únicamente con noticias acerca de la política, así que una opción a esto sería eliminar varias categorías de las noticias falsas, o bien, mantenerlas y decidir cuál específicamente son de política.\n",
    "\n",
    "Otra opción es predecir sin ocupar esta columna, para no tener ese \"spolier\" de ser una noticia falsa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento Preliminar de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+|\\$[\\d\\.]+|\\S+')\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "stop_words.add('thi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Obtener una submuestra de los dataframes originales\n",
    "df_true_ = df_true.copy()\n",
    "df_fake_ = df_fake.copy()\n",
    "\n",
    "df_true = df_true.sample(n=N_SAMPLES, random_state=SEED)\n",
    "df_fake = df_fake.sample(n=N_SAMPLES, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de las noticias falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar(df_a_proc, name_col,\n",
    "             verbose=True, msg_inicial=None, msg_final=None):\n",
    "    if verbose: print(msg_inicial)\n",
    "    col = df_a_proc[name_col]\n",
    "    for i, text in zip(col.index, col):\n",
    "        # Dejamos el texto en minusculas\n",
    "        text = text.lower()\n",
    "        # Tokenizamos\n",
    "        text_token = tokenizer.tokenize(text)\n",
    "        # Procesamos: stemmeamos las palabras que no sean stopwords, y unimos\n",
    "        text_proc = \" \".join([\n",
    "            lem.lemmatize(word, \n",
    "                          get_wordnet_pos(word)\n",
    "                         ) for word in text_token if word not in stop_words\n",
    "        ])\n",
    "        # Reemplazamos el texto procesado en el df a guardar\n",
    "        df_a_proc[name_col][i] = text_proc\n",
    "    if verbose: print(msg_final)\n",
    "    return df_a_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Titulares noticias falsas transformados\n",
    "if PROCESAR:\n",
    "    df_fake_proc = df_fake.copy()\n",
    "    \n",
    "    # Procesar el titulo\n",
    "    procesar(df_fake_proc, TITLE,\n",
    "             msg_inicial=\"Procesando los titulares falsos...\",\n",
    "             msg_final=\"Titulares falsos procesados!\")\n",
    "    \n",
    "    # Procesar el texto\n",
    "    procesar(df_fake_proc, TEXT,\n",
    "             msg_inicial=\"Procesando los textos falsos...\",\n",
    "             msg_final=\"Textos falsos procesados!\")\n",
    "    \n",
    "    if SAVE_DATAFRAME:\n",
    "        print(\"Guardando DataFrame procesado...\")\n",
    "        df_fake_proc.dropna(inplace=True)\n",
    "        df_fake_proc.to_csv(PATH_FAKE_PROS, index=False)\n",
    "        print(\"DataFrame procesado guardado!\")\n",
    "\n",
    "else:\n",
    "    print(\"Leyendo noticias falsas...\")\n",
    "    df_fake_proc = pd.read_csv(PATH_FAKE_PROS)\n",
    "    df_fake_proc.dropna(inplace=True)\n",
    "    print(\"Noticias falsas leidas!\")\n",
    "    \n",
    "df_fake_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prcesamiento de las noticias verdaderas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# titulares noticias verdaderas transformados\n",
    "if PROCESAR:\n",
    "    df_true_proc = df_true.copy()\n",
    "    \n",
    "    # Procesar el titulo\n",
    "    procesar(df_true_proc, TITLE,\n",
    "             msg_inicial=\"Procesando los titulares verdaderos...\",\n",
    "             msg_final=\"Titulares verdaderos procesados!\")\n",
    "    \n",
    "    # Procesar el texto\n",
    "    procesar(df_true_proc, TEXT,\n",
    "             msg_inicial=\"Procesando los textos verdaderos...\",\n",
    "             msg_final=\"Textos verdaderos procesados!\")\n",
    "    \n",
    "    if SAVE_DATAFRAME:\n",
    "        print(\"Guardando DataFrame procesado...\")\n",
    "        df_true_proc.dropna(inplace=True)\n",
    "        df_true_proc.to_csv(PATH_TRUE_PROS, index=False)\n",
    "        print(\"DataFrame procesado guardado!\")\n",
    "\n",
    "else:\n",
    "    print(\"Leyendo noticias verdaderas...\")\n",
    "    df_true_proc = pd.read_csv(PATH_TRUE_PROS)\n",
    "    df_true_proc.dropna(inplace=True)\n",
    "    print(\"Noticias verdaderas leidas!\")\n",
    "    \n",
    "df_true_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame procesado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df_true_proc.append(df_fake_proc, ignore_index=True)\n",
    "df_proc_ = df_proc\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis gráfico del tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones preliminares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotular(ax, title, xlabel, ylabel):\n",
    "    \"\"\"Rotula un gráfico\n",
    "    \"\"\"\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plot(ts_t, ts_f, \n",
    "            title=None, xlabel=None, ylabel=None, rotation=40,\n",
    "            save=SAVE_FIG, save_name=None,\n",
    "           ):\n",
    "    \"\"\"Plotea las cosas bajo el contexto que necesitamos.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()  # Create a figure containing a single axes.\n",
    "    ax.plot(ts_f)  # Plot some data on the axes.\n",
    "    ax.plot(ts_t)\n",
    "    ax.legend(['Falsa', 'Verdadera'], loc=\"best\")\n",
    "\n",
    "    plt.xticks(rotation=rotation)\n",
    "\n",
    "    rotular(ax, \n",
    "            title=title,\n",
    "            xlabel=xlabel,\n",
    "            ylabel=ylabel,)\n",
    "    \n",
    "    if save and save_name:\n",
    "        save_name = f\"{save_name}.pdf\"\n",
    "        save_path = path.join(PATH_IMG, save_name)\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con respecto a los dias de la semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "L_dow = [\"Monday\", \"Tuesday\", \"Wednesday\",\n",
    "         \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\", ]\n",
    "\n",
    "\n",
    "def count_dow(ser):\n",
    "    \"\"\"Cuenta los días de la semana y los rotúla.\n",
    "    \"\"\"\n",
    "    s = ser.dt.day_name().value_counts()\n",
    "    s = pd.Series({L_dow[i]: s[L_dow[i]] for i in range(7)})\n",
    "    return s\n",
    "\n",
    "\n",
    "ts_t = count_dow(df_true_[\"date\"])\n",
    "ts_f = count_dow(df_fake_[\"date\"])\n",
    "\n",
    "my_plot(ts_t, ts_f,\n",
    "        title=\"Comparación número de noticias por día de semana\",\n",
    "        xlabel=\"Día de la semana\",\n",
    "        ylabel=\"Número de noticias\",\n",
    "        save_name=\"numero_noticias_dia_semana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que las noticias verdaderas sacan noticas de forma constante, mientras que las noticias falsas tiene una baja de más del 50% en los fines de semana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con respecto a los meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "m = {\n",
    "    1: \"January\", 2: \"February\", 3: \"March\", 4: \"April\",\n",
    "    5: \"May\", 6: \"June\", 7: \"July\", 8: \"August\",\n",
    "    9: \"September\", 10: \"Octuber\", 11: \"November\", 12: \"December\"\n",
    "}\n",
    "\n",
    "def number2month(n):\n",
    "    \"\"\"Hace un mapeo del número de un mes, al nombre del mes.\n",
    "    Retorna None si no se entrega un número entero entre el 1 y el 12.\n",
    "    \"\"\"\n",
    "    return m.get(n, None)\n",
    "\n",
    "def count_month(ser):\n",
    "    \"\"\"Cuenta los meses y los rotúla.\n",
    "    \"\"\"\n",
    "    s = ser.dt.month.map(number2month).value_counts()\n",
    "    s = pd.Series({m[i]:s[m[i]] for i in range(1, 13)})\n",
    "    return s\n",
    "\n",
    "ts_f = count_month(df_fake_[\"date\"])\n",
    "ts_t = count_month(df_true_[\"date\"])\n",
    "\n",
    "my_plot(ts_t, ts_f, rotation=60,\n",
    "        title=\"Comparación número de noticias por mes\",\n",
    "        xlabel=\"Mes\",\n",
    "        ylabel=\"Número de noticias\",\n",
    "        save=True,\n",
    "        save_name=\"numero_noticias_mes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las noticias verdaderas se mantienen constantes en los meses, mientras que las noticias falsas se mantienen por debajo de las noticias verdaderas. Sin embargo, esta situación cambia en los últimos meses a partir de agosto. Se puede deber que en esos meses empezaron las presidenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con respecto a lo largo del tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_f = df_fake_[\"date\"].dropna().apply(\n",
    "    lambda x: pd.Timestamp(x.strftime(\"%Y-%m\"))\n",
    ").value_counts().reset_index().sort_values(by=['index'])\n",
    "\n",
    "ts_t = df_true_[\"date\"].dropna().apply(\n",
    "    lambda x: pd.Timestamp(x.strftime(\"%Y-%m\"))\n",
    ").value_counts().reset_index().sort_values(by=['index'])\n",
    "\n",
    "# Create a figure containing a single axes.\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(ts_f['index'], ts_f['date'], label= 'Falsa')  # Plot some data on the axes.\n",
    "ax.plot(ts_t['index'], ts_t['date'], label= 'Verdadera')\n",
    "ax.legend()\n",
    "\n",
    "rotular(ax,\n",
    "        title=\"Noticias por fecha de publicación\",\n",
    "        xlabel=\"Fecha de publicación\",\n",
    "        ylabel=\"Frecuencia\")\n",
    "\n",
    "save_name = \"noticias_fecha_publicacion.pdf\"\n",
    "save_path = path.join(PATH_IMG, save_name)\n",
    "plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nubes de palabras\n",
    "\n",
    "Se procederá a elaborar las nubes de palabras a partir del cuerpo y el título de las noticias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "stop_words.add('thi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def show_wordcloud(data, title=None,\n",
    "                   save=SAVE_FIG, save_name=None,):\n",
    "    \"\"\"\n",
    "    Retorna la visualización de una nube de palabras.\n",
    "\n",
    "    :Param data: str, string del texto que se busca visualizar. \n",
    "    :Param title: str, título de la figura generada.\n",
    "    \"\"\"\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stop_words,\n",
    "        max_words=200,\n",
    "        max_font_size=40,\n",
    "        scale=3,\n",
    "        random_state=1  # chosen at random by flipping a coin; it was heads\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    if title and False:\n",
    "        fig.suptitle(title, fontsize=20)\n",
    "        fig.subplots_adjust(top=2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "\n",
    "    if save and save_name:\n",
    "        save_name = f\"{save_name}.pdf\"\n",
    "        save_path = path.join(PATH_IMG, save_name)\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora para que el formato de entrada a la función que \n",
    "# genera las nubes de palabras sea el correcto, debemos unir la lista \n",
    "# en un solo string. \n",
    "\n",
    "FAKE_TITLE= \" \".join(list(df_fake_proc.title))\n",
    "TRUE_TITLE= \" \".join(list(df_true_proc.title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(TRUE_TITLE, \n",
    "               title= 'Titulares de noticias verdaderas',\n",
    "               save_name=\"wordcloud_titulares_verdaderas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(FAKE_TITLE, \n",
    "               title= 'Titulares de noticias falsas',\n",
    "               save_name=\"wordcloud_titulares_falsas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuerpo de la noticia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora para que el formato de entrada a la función que genera las nubes de \n",
    "# palabras sea el correcto, debemos unir la lista\n",
    "# en un solo string.\n",
    "\n",
    "FAKE_TEXT = \" \".join(list(df_fake_proc.text))\n",
    "TRUE_TEXT = \" \".join(list(df_true_proc.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(TRUE_TEXT,\n",
    "               title='Cuerpo de noticias verdaderas',\n",
    "               save_name=\"wordclouds_cuerpo_verdaderas\"\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(FAKE_TEXT,\n",
    "               title= 'Cuerpo de noticias falsas',\n",
    "               save_name=\"wordclouds_cuerpo_falsas\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos de distribución de frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(data, n, col,\n",
    "                   save=SAVE_FIG, save_name=None,):\n",
    "    word_array = []\n",
    "    for row in data[col]:\n",
    "        for word in row.split(' '):\n",
    "            word_array.append(word)\n",
    "    print(f'- Frecuencia por {col}:')\n",
    "    FreqDist(word_array).plot(n)\n",
    "    \n",
    "    if save and save_name:\n",
    "        save_name = f\"{save_name}.pdf\"\n",
    "        save_path = path.join(PATH_IMG, save_name)\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NOTICIAS VERDADERAS')\n",
    "word_frequency(df_true_proc, 10, \"title\",\n",
    "               save_name=\"freq_title_true\")\n",
    "\n",
    "word_frequency(df_true_proc, 10, \"text\",\n",
    "               save_name=\"freq_text_true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NOTICIAS FALSAS')\n",
    "word_frequency(df_fake_proc, 10, \"title\",\n",
    "               save_name=\"freq_title_fake\")\n",
    "\n",
    "word_frequency(df_fake_proc, 10, \"text\",\n",
    "               save_name=\"freq_text_fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TODAS LAS NOTICIAS')\n",
    "word_frequency(df_proc, 10, \"title\",\n",
    "               save_name=\"freq_title_all\")\n",
    "\n",
    "word_frequency(df_proc, 10, \"text\",\n",
    "               save_name=\"freq_text_all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el texto tokenizado, se formará un conjunto de $k$ variables que representará a cada una de las palabras (distintas) presentes en el conjunto de noticias (cada palabra será una característica). Dicha asociación palabra-variable puede encontrarse en **vectorizer.get_feature_names()** donde el orden de las palabras corresponde a su variable asociada.\n",
    "\n",
    "Luego, se transformará cada noticia en un vector de $\\mathbb{N_0}^k$ donde la $i$-ésima entrada corresponderá a la cantidad de apariciones de la $i$-ésima en la noticia. De este modo, se tiene una única matriz (**encoded_data**) que almacenará cada una de las noticias, lo cual permitirá realizar regresión logística para obtener el clasificador buscado.\n",
    "\n",
    "Lo único que falta definir es de qué modo se van a entregar los elementos de cada noticia (título y cuerpo). Se proponen las siguientes opciones:\n",
    "\n",
    "1. Entregar solo los títulos.\n",
    "2. Entregar solo los cuerpos (contenido).\n",
    "3. Entregar título y cuerpo como una única cadena (concatenada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_encoding(data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    # matriz de características.\n",
    "    encoded_data = vectorizer.fit_transform(data).toarray()\n",
    "    print('Características totales:', len(vectorizer.get_feature_names()))\n",
    "\n",
    "    print('Características promedio por noticia:')\n",
    "    print('- Ponderado:',\n",
    "          np.round(\n",
    "              np.mean([sum(news_item) for news_item in encoded_data]), 2\n",
    "          )\n",
    "         )\n",
    "    print('- Simple:',\n",
    "          np.round(\n",
    "              np.mean(\n",
    "                  [np.count_nonzero(news_item) for news_item in encoded_data]\n",
    "              ), 2)\n",
    "         )\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dict()\n",
    "\n",
    "print('\\nSOLO TÍTULOS')\n",
    "X['title'] = data_encoding(df_proc_['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSOLO CUERPO')\n",
    "X['text'] = data_encoding(df_proc_['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTITULOS Y CUERPO')\n",
    "X['title_text'] = data_encoding(\n",
    "    [news_item for news_item in df_proc_['title'] + ' ' + df_proc_['text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clasificación real:\n",
    "y = list(df_proc_['true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_list = [\"title\", \"text\", \"title & text\"]\n",
    "modelos_list = [\"Regresion Logistica\", \"Naive Bayes\", \"Perceptron\", \"SVC\"]\n",
    "resultados = {\n",
    "    columna: {\n",
    "        modelo: 0 for modelo in modelos_list\n",
    "    } for columna in columnas_list\n",
    "}\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def classification(x):\n",
    "\n",
    "    # partición del conjunto:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "    print('\\nTotal de datos:', len(y))\n",
    "    print('- Datos de entrenamiento:', len(y_train))\n",
    "    print('- Datos de validación:', len(y_test))\n",
    "\n",
    "    # clasificación:\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    def classifier_evaluation(x_eval, y_eval):\n",
    "\n",
    "        # predicciones y probabilidades de acierto para x_eval:\n",
    "        y_pred = classifier.predict(x_eval)\n",
    "        y_prob = classifier.predict_proba(x_eval)*100\n",
    "        \n",
    "        precision = np.round(accuracy_score(y_eval, y_pred)*100,2)\n",
    "        print(f'- Precisión (fracción): {precision}%')\n",
    "        \n",
    "        prob_acierto = np.round(np.mean([max(prob) for prob in y_prob]),2)\n",
    "        print(f'- Probabilidad de acierto media: {prob_acierto}%')\n",
    "        \n",
    "        conf_matriz = classification_report(y_eval, y_pred)\n",
    "        print(f'- Matriz de confusion: \\n{conf_matriz}') \n",
    "\n",
    "        return precision\n",
    "\n",
    "    print('\\nEvaluación dentro de muestra:')\n",
    "    classifier_evaluation(x_train, y_train)\n",
    "\n",
    "    print('\\nEvaluación fuera de muestra:')\n",
    "    precision = classifier_evaluation(x_test, y_test)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSOLO TÍTULOS')\n",
    "resultados[\"title\"][\"Regresion Logistica\"] = classification(X['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSOLO CUERPO')\n",
    "resultados[\"text\"][\"Regresion Logistica\"] = classification(X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTITULOS Y CUERPO')\n",
    "resultados[\"title & text\"][\"Regresion Logistica\"] = classification(X['title_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(x):\n",
    "\n",
    "    # partición del conjunto:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "    print('\\nTotal de datos:', len(y))\n",
    "    print('- Datos de entrenamiento:', len(y_train))\n",
    "    print('- Datos de validación:', len(y_test))\n",
    "\n",
    "    # clasificación:\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    def classifier_evaluation(x_eval, y_eval):\n",
    "\n",
    "        # predicciones y probabilidades de acierto para x_eval:\n",
    "        y_pred = classifier.predict(x_eval)\n",
    "        y_prob = classifier.predict_proba(x_eval)*100\n",
    "        \n",
    "        precision = np.round(accuracy_score(y_eval, y_pred)*100,2)\n",
    "        print(f'- Precisión (fracción): {precision}%')\n",
    "        \n",
    "        prob_acierto = np.round(np.mean([max(prob) for prob in y_prob]),2)\n",
    "        print(f'- Probabilidad de acierto media: {prob_acierto}%')\n",
    "        \n",
    "        conf_matriz = classification_report(y_eval, y_pred)\n",
    "        print(f'- Matriz de confusion: \\n{conf_matriz}') \n",
    "        \n",
    "        return precision\n",
    "\n",
    "    print('\\nEvaluación dentro de muestra:')\n",
    "    classifier_evaluation(x_train, y_train)\n",
    "\n",
    "    print('\\nEvaluación fuera de muestra:')\n",
    "    precision = classifier_evaluation(x_test, y_test)\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSOLO TÍTULOS')\n",
    "resultados[\"title\"][\"Naive Bayes\"] = classification(X['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSOLO CUERPO')\n",
    "resultados[\"text\"][\"Naive Bayes\"] = classification(X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTITULOS Y CUERPO')\n",
    "resultados[\"title & text\"][\"Naive Bayes\"] = classification(X['title_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(x):\n",
    "    from sklearn.linear_model import Perceptron\n",
    "    # partición del conjunto:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "    print('\\nTotal de datos:', len(y))\n",
    "    print('- Datos de entrenamiento:', len(y_train))\n",
    "    print('- Datos de validación:', len(y_test))\n",
    "\n",
    "    # clasificación:\n",
    "    classifier = Perceptron()\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    def classifier_evaluation(x_eval, y_eval):\n",
    "\n",
    "        # predicciones y probabilidades de acierto para x_eval:\n",
    "        y_pred = classifier.predict(x_eval)\n",
    "#         y_prob = classifier.predict_proba(x_eval)*100\n",
    "        \n",
    "        precision = np.round(accuracy_score(y_eval, y_pred)*100,2)\n",
    "        print(f'- Precisión (fracción): {precision}%')\n",
    "        \n",
    "#         prob_acierto = np.round(np.mean([max(prob) for prob in y_prob]),2)\n",
    "#         print(f'- Probabilidad de acierto media: {prob_acierto}%')\n",
    "        \n",
    "        conf_matriz = classification_report(y_eval, y_pred)\n",
    "        print(f'- Matriz de confusion: \\n{conf_matriz}') \n",
    "        \n",
    "        return precision\n",
    "\n",
    "    print('\\nEvaluación dentro de muestra:')\n",
    "    classifier_evaluation(x_train, y_train)\n",
    "\n",
    "    print('\\nEvaluación fuera de muestra:')\n",
    "    precision = classifier_evaluation(x_test, y_test)\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSOLO TÍTULOS')\n",
    "resultados[\"title\"][\"Perceptron\"] = classification(X['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSOLO CUERPO')\n",
    "resultados[\"text\"][\"Perceptron\"] = classification(X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTITULOS Y CUERPO')\n",
    "resultados[\"title & text\"][\"Perceptron\"] = classification(X['title_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(x):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    \n",
    "    # partición del conjunto:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "    print('\\nTotal de datos:', len(y))\n",
    "    print('- Datos de entrenamiento:', len(y_train))\n",
    "    print('- Datos de validación:', len(y_test))\n",
    "\n",
    "    # clasificación:\n",
    "    classifier = LinearSVC()\n",
    "    classifier.fit(x_train, y_train)\n",
    "\n",
    "    def classifier_evaluation(x_eval, y_eval):\n",
    "\n",
    "        # predicciones y probabilidades de acierto para x_eval:\n",
    "        y_pred = classifier.predict(x_eval)\n",
    "#         y_prob = classifier.predict_proba(x_eval)*100\n",
    "        \n",
    "        precision = np.round(accuracy_score(y_eval, y_pred)*100,2)\n",
    "        print(f'- Precisión (fracción): {precision}%')\n",
    "        \n",
    "#         prob_acierto = np.round(np.mean([max(prob) for prob in y_prob]),2)\n",
    "#         print(f'- Probabilidad de acierto media: {prob_acierto}%')\n",
    "        \n",
    "        conf_matriz = classification_report(y_eval, y_pred)\n",
    "        print(f'- Matriz de confusion: \\n{conf_matriz}') \n",
    "        return precision\n",
    "\n",
    "    print('\\nEvaluación dentro de muestra:')\n",
    "    classifier_evaluation(x_train, y_train)\n",
    "\n",
    "    print('\\nEvaluación fuera de muestra:')\n",
    "    precision = classifier_evaluation(x_test, y_test)\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSOLO TÍTULOS')\n",
    "resultados[\"title\"][\"SVC\"] = classification(X['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nSOLO CUERPO')\n",
    "resultados[\"text\"][\"SVC\"] = classification(X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTITULOS Y CUERPO')\n",
    "resultados[\"title & text\"][\"SVC\"] = classification(X['title_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(resultados)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = path.join(PATH_TABLAS, \"tabla_resumen.tex\")\n",
    "\n",
    "res.to_latex(save_name,\n",
    "             column_format=\"rccc\",\n",
    "             caption=\"Tabla de Resumen\",\n",
    "             label=\"tab:resumen\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial nltk \n",
    "\n",
    "Vale: Ya hice algunos imports y le cambié el nombre a algunas funciones que tenían nombre muy largo. Así que ahora lo voy a explicar: \n",
    "\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\") \n",
    "\n",
    "Lo que hace es separar un string de un párrafo u oración en una lista de strings con las palabras. La diferencia con la función 'word_tokenize', es que RegexpTokenize puede configurarse para aceptar solamente ciertos caracteres. El argumento r\"\\w+\" es para que ignore la puntuación del texto y no la incluya en la lista. Sé que también se puede configurar para ignorar los números, habría que buscar en google el argumento correcto. \n",
    "\n",
    "stem = PorterStemmer()\n",
    "\n",
    "Lo que hace es devolver una palabra o verbo conjugado a su palabra raíz.\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "Lo que hace es devolver una palabra o verbo conjugado a su palabra raíz. Dependiendo del segundo argumento que reciba (el primer argumento en el texto como string) puede definir las raices como verbos, pronombres, etc. A diferencia de steamming, relaciona las palabras con su significado, no solamente a partir de la gramática. Esta página (https://www.machinelearningplus.com/nlp/lemmatization-examples-python/) explica que para hacerlo bien hay que usar POS tag, que es otra función que detecta si la palabra es adjetivo, adverbio, sustantivo o verbo, y así WordNetLemmatizer() se puede llamar de forma adecuada para cada palabra.\n",
    "\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "Es un set con los pronombres, preposiciones, y otro tipo de palabras que no aportan valor. Usando add se pueden incluir palabras nuevas. \n",
    "\n",
    "A continuación un ejemplo de uso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt= df[TITLE][325]\n",
    "\n",
    "print ( 'El texto original es: ' + txt + '\\n')\n",
    "\n",
    "token_txt= tokenizer.tokenize(txt)\n",
    "\n",
    "print('El texto toquenizado es: ' )\n",
    "print(token_txt)\n",
    "print('\\n')\n",
    "\n",
    "stop_txt=[]\n",
    "for i in token_txt: \n",
    "    if i not in stop_words:\n",
    "        stop_txt.append(i)\n",
    "\n",
    "print('El texto sin stop words es: ' )\n",
    "print(stop_txt)\n",
    "print('\\n')\n",
    "\n",
    "stem_txt= []\n",
    "for i in stop_txt:\n",
    "    stem_txt.append(stem.stem(i))\n",
    "    \n",
    "print('El texto stemizado es: ' )\n",
    "print(stem_txt)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PD: Cuando estaba programando las nubes de palabras, me di cuenta de que en las noticias falsas, los títulos van siempre con la primera letra de cada palabra en mayúscula (y en las noticias verdaderas no pasa). Podríamos hacer una predicción sin cambiar eso, para ver si considera las mayúsculas como importantes y después otra usando todo en minúscula, porque igual es la media trampa. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.727px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
